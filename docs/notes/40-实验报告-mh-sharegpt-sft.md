## å®éªŒæŠ¥å‘Šï¼šmh-sharegpt SFTï¼ˆLoRAï¼‰

### 1. å®éªŒæ¦‚è¿°
- **ç›®æ ‡**ï¼šåŸºäº ShareGPT æ•°æ®é›†è¿›è¡Œå¯¹è¯æ¨¡å‹çš„æŒ‡ä»¤å¾®è°ƒï¼ˆSFTï¼‰ï¼ŒéªŒè¯è®­ç»ƒé“¾è·¯ã€ç›‘æ§ä¸å¯¼å‡ºæµç¨‹ã€‚
- **æ•°æ®é›†**ï¼š`CodyWhy/mh-sharegpt-20250820`
- **åŸºåº§æ¨¡å‹ï¼ˆç¤ºä¾‹ï¼‰**ï¼š`Qwen/Qwen2.5-7B-Instruct`ï¼ˆ7Bï¼‰ï¼Œä»¥åŠ 32B å˜ä½“
- **è®­ç»ƒç±»å‹**ï¼šLoRAï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰
- **ç›‘æ§**ï¼šSwanLabï¼ˆäº‘ç«¯ï¼‰ï¼Œå¿…é¡»æ˜¾å¼ `--report_to swanlab`

å…³è”æ–‡æ¡£ï¼š
- æ•°æ®ä¸è®­ç»ƒæµç¨‹ï¼š`notes/20-æ•°æ®ä¸SFTè®­ç»ƒ.md`
- SwanLab é›†æˆï¼š`notes/30-SwanLabé›†æˆ.md`
- Flash Attention å®‰è£…ï¼š`notes/50-FlashAttentionå®‰è£….md`
- å¯†é’¥ä¸æ•°æ®ç´¢å¼•ï¼ˆç§å¯†ï¼‰ï¼š`notes/90-å¯†é’¥ä¸æ•°æ®ç´¢å¼•.md`

### 2. ç¯å¢ƒä¸ä¾èµ–
- ms-swiftï¼šå»ºè®®æœ€æ–°ç‰ˆæœ¬ï¼ˆå‚è€ƒ `pip install -U ms-swift`ï¼‰
- ModelScopeï¼šç”¨äºç™»å½•ä¸æ•°æ®é›†è®¿é—®ï¼ˆå¯é€‰ï¼‰
- SwanLabï¼šç”¨äºå®éªŒè®°å½•ä¸å¯è§†åŒ–
- Flash Attentionï¼šæ”¯æŒ `--packing true` åŠŸèƒ½ï¼ˆå·²å®‰è£…ï¼‰
- å»ºè®®é€šè¿‡ `.env` ç®¡ç†æ•æ„Ÿä¿¡æ¯ï¼š`SWANLAB_API_KEY`ã€`MODELSCOPE_API_TOKEN`ã€`DATASET_ID`

### 3. æ•°æ®
- æ•°æ®æ ¼å¼ï¼šShareGPTï¼ˆAutoPreprocessor è‡ªåŠ¨è¯†åˆ«ï¼Œæ— éœ€æ‰‹åŠ¨è½¬æ¢ï¼‰
- æ•°æ®é›† IDï¼š`CodyWhy/mh-sharegpt-20250820`
- æœ¬åœ°æ•°æ®ä¹Ÿå¯ç›´æ¥è®­ç»ƒï¼›è‹¥éœ€å…±äº«/å¤ç”¨ï¼Œå¯ä¸Šä¼ åˆ° ModelScope

### 4. Flash Attention çŠ¶æ€
- **çŠ¶æ€**ï¼šâœ… å·²å®‰è£…
- **ç‰ˆæœ¬**ï¼š2.6.3+cu124torch2.6-cp310
- **å®‰è£…æ–¹å¼**ï¼šé¢„ç¼–è¯‘ wheelï¼ˆghproxy.net ä»£ç†ï¼‰
- **éªŒè¯å‘½ä»¤**ï¼š`python -c "import flash_attn, flash_attn_cuda; print('OK')"`
- **æ”¯æŒåŠŸèƒ½**ï¼š`--packing true` + `--attn_impl flash_attn`

### 5. è®­ç»ƒé…ç½®ä¸å‘½ä»¤

#### 5.1 æœ€å°å¯è¡Œï¼ˆ7Bï¼Œå•å¡ï¼Œæ”¯æŒ packingï¼‰
```bash
CUDA_VISIBLE_DEVICES=6 \
swift sft \
  --model Qwen/Qwen2.5-7B-Instruct \
  --train_type lora \
  --dataset CodyWhy/mh-sharegpt-20250820 \
  --num_train_epochs 1 \
  --per_device_train_batch_size 8 \
  --gradient_accumulation_steps 4 \
  --learning_rate 2e-4 \
  --max_length 3072 \
  --packing true \
  --attn_impl flash_attn \
  --bf16 true \
  --gradient_checkpointing true \
  --save_steps 200 \
  --save_total_limit 3 \
  --logging_steps 20 \
  --output_dir output/mh-sft-7b-lora \
  --report_to swanlab \
  --swanlab_token ${SWANLAB_API_KEY} \
  --swanlab_project ${SWANLAB_PROJECT:-mh-sft} \
  --swanlab_mode ${SWANLAB_MODE:-cloud} \
  --swanlab_exp_name mh-sft-qwen2p5-7b-lora
```

#### 5.2 32Bï¼ˆH100 80GBï¼Œç¤ºä¾‹ä¸º 6 å·å¡ï¼‰
```bash
CUDA_VISIBLE_DEVICES=6 \
swift sft \
  --model Qwen/Qwen2.5-32B-Instruct \
  --train_type lora \
  --dataset CodyWhy/mh-sharegpt-20250820 \
  --bf16 true \
  --max_length 4096 \
  --packing true \
  --attn_impl flash_attn \
  --gradient_checkpointing true \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 8 \
  --learning_rate 2e-4 \
  --num_train_epochs 1 \
  --save_steps 200 \
  --save_total_limit 3 \
  --logging_steps 20 \
  --output_dir output/mh-sft-32b-lora \
  --report_to swanlab \
  --swanlab_token ${SWANLAB_API_KEY} \
  --swanlab_project ${SWANLAB_PROJECT:-mh-sft} \
  --swanlab_mode ${SWANLAB_MODE:-cloud} \
  --swanlab_exp_name mh-sft-qwen2p5-32b-lora
```

#### 5.3 ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼ˆå¯æ›¿ä»£æ•°æ®é›† IDï¼‰
```bash
CUDA_VISIBLE_DEVICES=6 \
swift sft \
  --model Qwen/Qwen2.5-7B-Instruct \
  --train_type lora \
  --dataset /abs/path/to/your_sharegpt.jsonl \
  --num_train_epochs 1 \
  --per_device_train_batch_size 8 \
  --gradient_accumulation_steps 4 \
  --learning_rate 2e-4 \
  --max_length 3072 \
  --packing true \
  --attn_impl flash_attn \
  --bf16 true \
  --gradient_checkpointing true \
  --output_dir output/local-file-run \
  --report_to swanlab \
  --swanlab_token ${SWANLAB_API_KEY} \
  --swanlab_project ${SWANLAB_PROJECT:-mh-sharegpt} \
  --swanlab_mode ${SWANLAB_MODE:-cloud} \
  --swanlab_exp_name mh-sft-local-file
```

### 6. ç›‘æ§ä¸éªŒè¯
- å¿…é¡»æ˜¾å¼åŠ å…¥ï¼š`--report_to swanlab`ï¼Œå¦åˆ™ä¸ä¼šæ¨é€ä»»ä½•æŒ‡æ ‡
- è¿è¡Œæ—¶é¢„æœŸæ—¥å¿—ï¼š
```text
[swanlab] experiment created: project=mh-sft, exp_name=...
[swanlab] uploading metrics ...
```
- Python æœ¬åœ°è¿é€šæ€§æµ‹è¯•ç¤ºä¾‹è§ï¼š`notes/30-SwanLabé›†æˆ.md`

### 7. æ¨ç†ä¸å¯¼å‡º

#### 7.1 æ¨ç†æµ‹è¯•ï¼ˆ2025-08-20 å®Œæˆï¼‰

**æµ‹è¯•ç¯å¢ƒ**ï¼š
- GPU: NVIDIA H100 (å¡å· 6)
- æ¨¡å‹: Qwen/Qwen2.5-7B-Instruct + LoRA checkpoint-508
- æ£€æŸ¥ç‚¹è·¯å¾„: `./output/mh-sft/v0-20250820-144506/checkpoint-508`

**æ¨ç†æ–¹å¼å¯¹æ¯”**ï¼š

1) **PyTorch åç«¯ï¼ˆå¯åŠ¨æœ€å¿«ï¼‰**
```bash
CUDA_VISIBLE_DEVICES=6 \
swift infer \
  --model Qwen/Qwen2.5-7B-Instruct \
  --adapters ./output/mh-sft/v0-20250820-144506/checkpoint-508 \
  --infer_backend pt \
  --attn_impl flash_attn \
  --stream true \
  --max_new_tokens 512
```

2) **SGLang åç«¯ï¼ˆå¹¶å‘æ€§èƒ½å¥½ï¼‰**
```bash
CUDA_VISIBLE_DEVICES=6 \
swift deploy \
  --model Qwen/Qwen2.5-7B-Instruct \
  --adapters ./output/mh-sft/v0-20250820-144506/checkpoint-508 \
  --infer_backend sglang \
  --served_model_name mh-sft-7b
```

3) **LMDeploy åç«¯ï¼ˆæ¨èï¼Œå¯åŠ¨å¿«+æ€§èƒ½å¥½ï¼‰**
```bash
CUDA_VISIBLE_DEVICES=6 \
swift deploy \
  --model Qwen/Qwen2.5-7B-Instruct \
  --adapters ./output/mh-sft/v0-20250820-144506/checkpoint-508 \
  --infer_backend lmdeploy \
  --served_model_name mh-sft-7b \
  --tp 1 \
  --cache-max-entry-count 0 \
  --session-len 4096
```

**æ¨ç†æµ‹è¯•ç»“æœ**ï¼š
- âœ… æ‰€æœ‰åç«¯å‡æˆåŠŸåŠ è½½ LoRA æƒé‡
- âœ… ä¸­æ–‡è¾“å…¥è¾“å‡ºæ­£å¸¸ï¼ˆlocale å·²ä¿®å¤ï¼‰
- âœ… Flash Attention æ­£å¸¸å·¥ä½œ
- âœ… æ¨ç†è´¨é‡ç¬¦åˆé¢„æœŸ

#### 7.2 æ¨¡å‹å¯¼å‡º

1) **åˆå¹¶ LoRA æƒé‡**
```bash
swift export \
  --ckpt_dir ./output/qwen2.5-7b-sft/v0-20250824-022332/checkpoint-43 \
  --merge_lora true \
  --safe_serialization true \
  --max_shard_size 2GB \
  --output_dir ./export/qwen-sft-7b
```

2) **ä¸Šä¼ åˆ° ModelScope**
```bash
swift upload \
  --model_dir ./export/qwen-sft-7b \
  --hub modelscope \
  --model_id yourname/qwen-sft-7b
```

3) **ä¸Šä¼ åˆ° HuggingFace**
```bash
huggingface-cli upload ./export/qwen-sft-7b yourname/qwen-sft-7b
```

## 8. æ¨¡å‹è¯„æµ‹ï¼ˆ2025-08-20 å®Œæˆï¼‰

### 8.1 è¯„æµ‹ç¯å¢ƒå‡†å¤‡

**ç¯å¢ƒå˜é‡è®¾ç½®**ï¼ˆè§£å†³ä»£ç†é—®é¢˜ï¼‰ï¼š
```bash
# è®¾ç½®æœ¬åœ°åœ°å€ä¸èµ°ä»£ç†
export NO_PROXY=127.0.0.1,localhost,::1
export no_proxy=$NO_PROXY

# éªŒè¯è®¾ç½®
echo "NO_PROXY: $NO_PROXY"
echo "no_proxy: $no_proxy"
```

**æœåŠ¡å¯åŠ¨**ï¼ˆLMDeploy åç«¯ï¼‰ï¼š
```bash
CUDA_VISIBLE_DEVICES=6 \
swift deploy \
  --model Qwen/Qwen2.5-7B-Instruct \
  --adapters ./output/mh-sft/v0-20250820-144506/checkpoint-508 \
  --infer_backend lmdeploy \
  --served_model_name mh-sft-7b \
  --tp 1 \
  --cache-max-entry-count 0 \
  --session-len 4096
```

**æœåŠ¡å¥åº·æ£€æŸ¥**ï¼š
```bash
# æµ‹è¯• /models æ¥å£
curl --noproxy '*' http://127.0.0.1:8000/v1/models

# æµ‹è¯•æ¨ç†æ¥å£
curl --noproxy '*' http://127.0.0.1:8000/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -d '{"model":"mh-sft-7b","messages":[{"role":"user","content":"ä½ å¥½"}]}'
```

### 8.2 è¯„æµ‹å·¥å…·å®‰è£…ä¸é…ç½®

#### æ–¹æ¡ˆ Aï¼šlm-eval-harnessï¼ˆæ¨èï¼Œå¿«é€Ÿæµ‹è¯•ï¼‰

**å®‰è£…**ï¼š
```bash
pip install "lm-eval==0.4.2"
```

**å‡†å¤‡è¯„æµ‹æ•°æ®**ï¼š
åˆ›å»º `data/pceb_mcq.jsonl`ï¼š
```json
{"id":"q1","question":"æ±‚åŠ©è€…å› å‡ºå›½ä¸å®¶åº­çŸ›ç›¾äº§ç”Ÿçš„å¿ƒç†å†²çªç±»å‹æ˜¯ï¼Ÿ","choices":["å˜å½¢","è¶‹é¿å¼","å¸¸å½¢","åŒè¶‹å¼"],"answer":"B"}
{"id":"q2","question":"å¿ƒç†å’¨è¯¢ä¸­ï¼Œå…±æƒ…æ˜¯æŒ‡ï¼Ÿ","choices":["åŒæƒ…","ç†è§£","æŒ‡å¯¼","åˆ†æ"],"answer":"B"}
```

**å®šä¹‰è¯„æµ‹ä»»åŠ¡**ï¼š
åˆ›å»º `tasks/pceb_mcq.yaml`ï¼š
```yaml
task: pceb_mcq
dataset_path: data/pceb_mcq.jsonl
output_type: multiple_choice
doc_to_text: "é—®ï¼š{{question}}\né€‰é¡¹ï¼š{% for c in choices %}{{ loop.index0 | chr(65) }}. {{ c }} {% endfor %}\nç­”ï¼š"
doc_to_target: "{{answer}}"
doc_to_choice: "{{choices}}"
should_decontaminate: false
fewshot_delimiter: "\n\n"
generation_kwargs:
  temperature: 0.0
```

**è¿è¡Œè¯„æµ‹**ï¼š
```bash
# ä½¿ç”¨æœ¬åœ°æœåŠ¡
lm_eval \
  --model openai-chat-completions \
  --model_args api_base=http://127.0.0.1:8000/v1,model=mh-sft-7b \
  --tasks pceb_mcq \
  --num_fewshot 0 \
  --batch_size 1

# æˆ–ä½¿ç”¨åˆå¹¶åçš„æƒé‡
lm_eval \
  --model hf \
  --model_args pretrained=./export/mh-sft-qwen2p5-7b,dtype=bfloat16,attn_implementation=flash_attention_2 \
  --tasks pceb_mcq \
  --num_fewshot 0 \
  --batch_size 1
```

#### æ–¹æ¡ˆ Bï¼šEvalScopeï¼ˆå®Œæ•´è¯„æµ‹ï¼‰

**å®‰è£…**ï¼š
```bash
# åŸºç¡€ç‰ˆæœ¬
pip install evalscope

# å¸¦å¯è§†åŒ–ç•Œé¢çš„å®Œæ•´ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
pip install 'evalscope[app]'
```

**ä½¿ç”¨å¯¼å‡ºæ¨¡å‹è¿›è¡Œè¯„æµ‹**ï¼š

ç”±äºæˆ‘ä»¬å·²ç»å¯¼å‡ºäº†å®Œæ•´çš„æ¨¡å‹æƒé‡ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ EvalScope è¿›è¡Œè¯„æµ‹ï¼Œæ— éœ€å¯åŠ¨æœåŠ¡ï¼š

```bash
# 1. ç›´æ¥è¯„æµ‹å¯¼å‡ºæ¨¡å‹ï¼ˆæ¨èï¼‰
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval cmmlu \
  --limit 100 \
  --output-file ./results/mh-sft-7b-ceval-cmmlu.json

# 2. è¯„æµ‹å¿ƒç†å­¦åŸºå‡†ï¼ˆå¦‚æœæ”¯æŒï¼‰
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets pceb_mcq psyqa \
  --limit 100 \
  --output-file ./results/mh-sft-7b-psychology.json

# 3. è¯„æµ‹å¤šä¸ªæ•°æ®é›†
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval cmmlu pceb_mcq psyqa \
  --limit 100 \
  --output-file ./results/mh-sft-7b-all-benchmarks.json
```

**è¯„æµ‹ç»“æœå¯è§†åŒ–**ï¼š
```bash
# å¯åŠ¨ EvalScope å¯è§†åŒ–ç•Œé¢
evalscope app --lang zh

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://127.0.0.1:7860
# ä¸Šä¼ è¯„æµ‹ç»“æœæ–‡ä»¶è¿›è¡Œå¯è§†åŒ–åˆ†æ
```

**è¯„æµ‹å‚æ•°è¯´æ˜**ï¼š
- `--model`: å¯¼å‡ºæ¨¡å‹çš„æœ¬åœ°è·¯å¾„
- `--eval-type local`: ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆè€Œé API æœåŠ¡ï¼‰
- `--datasets`: è¦è¯„æµ‹çš„æ•°æ®é›†åˆ—è¡¨
- `--limit`: æ¯ä¸ªæ•°æ®é›†çš„è¯„æµ‹æ ·æœ¬æ•°é‡
- `--output-file`: è¯„æµ‹ç»“æœä¿å­˜è·¯å¾„

**æ”¯æŒçš„å¿ƒç†å­¦åŸºå‡†æ•°æ®é›†**ï¼š
- `ceval`: ä¸­æ–‡è¯­è¨€ç†è§£è¯„ä¼°åŸºå‡†
- `cmmlu`: ä¸­æ–‡å¤šä»»åŠ¡è¯­è¨€ç†è§£
- `pceb_mcq`: å¿ƒç†å­¦è€ƒè¯•é€‰æ‹©é¢˜
- `psyqa`: å¿ƒç†å­¦é—®ç­”æ•°æ®é›†

**è¿è¡Œè¯„æµ‹**ï¼š
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡åè¿è¡Œ
export NO_PROXY=127.0.0.1,localhost,::1
export no_proxy=$NO_PROXY

evalscope eval \
  --model mh-sft-7b \
  --api-url http://127.0.0.1:8000/v1 \
  --api-key EMPTY \
  --eval-type service \
  --datasets ceval cmmlu \
  --limit 100
```

**ç»“æœå¯è§†åŒ–**ï¼š
```bash
# å¯åŠ¨å¯è§†åŒ–ç•Œé¢ï¼ˆä¸­æ–‡ï¼‰
evalscope app --lang zh

# å¯åŠ¨å¯è§†åŒ–ç•Œé¢ï¼ˆè‹±æ–‡ï¼‰
evalscope app --lang en
```

**å¯è§†åŒ–åŠŸèƒ½**ï¼š
- ğŸ“Š **è¯„æµ‹æŒ‡æ ‡å›¾è¡¨**ï¼šå‡†ç¡®ç‡ã€F1ã€BLEU ç­‰æŒ‡æ ‡çš„è¶‹åŠ¿å›¾
- ğŸ” **è¯¦ç»†è¾“å‡ºå¯¹æ¯”**ï¼šæŸ¥çœ‹æ¨¡å‹åœ¨æ¯ä¸ªæ ·æœ¬ä¸Šçš„å…·ä½“å›ç­”
- ğŸ“ˆ **æ€§èƒ½åˆ†æ**ï¼šä¸åŒæ•°æ®é›†ã€ä¸åŒç»´åº¦çš„æ€§èƒ½å¯¹æ¯”
- ğŸ’¾ **ç»“æœå¯¼å‡º**ï¼šæ”¯æŒ CSVã€JSON ç­‰æ ¼å¼çš„ç»“æœå¯¼å‡º
- ğŸ¯ **é”™è¯¯åˆ†æ**ï¼šé‡ç‚¹å…³æ³¨é”™è¯¯æ ·æœ¬ï¼Œåˆ†ææ¨¡å‹å¼±ç‚¹

### 8.3 è¯„æµ‹ç»“æœè®°å½•

**é€‰æ‹©é¢˜è¯„æµ‹æŒ‡æ ‡**ï¼š
- æ ‡å‡†å‡†ç¡®ç‡ï¼ˆexact matchï¼‰
- å¼¹æ€§å‡†ç¡®ç‡ï¼ˆsubset/overlapï¼Œå¤šé€‰é¢˜éƒ¨åˆ†åˆ†ï¼‰

**ä¸»è§‚é¢˜è¯„æµ‹æŒ‡æ ‡**ï¼š
- Rouge-1 / Rouge-L / BLEU
- è¦ç‚¹å‘½ä¸­ç‡

**å¿ƒç†å­¦ä¸“ç”¨ç»´åº¦**ï¼š
- æƒ…ç»ªå…±æƒ… (EmoE)
- è®¤çŸ¥å…±æƒ… (CogE)
- å¯¹è¯ç­–ç•¥ (Con.)
- æ€åº¦ä¸çŠ¶æ€ (Sta.)
- å®‰å…¨æ€§ (Saf.)

**ç»“æœå¯è§†åŒ–ä¸åˆ†æ**ï¼š
- ğŸ“Š **EvalScope å¯è§†åŒ–ç•Œé¢**ï¼š`evalscope app --lang zh`
- ğŸ“ˆ **æ€§èƒ½è¶‹åŠ¿å›¾**ï¼šä¸åŒæ•°æ®é›†ã€ä¸åŒç»´åº¦çš„æ€§èƒ½å¯¹æ¯”
- ğŸ” **æ ·æœ¬çº§åˆ†æ**ï¼šæŸ¥çœ‹å…·ä½“é—®ç­”å¯¹ï¼Œåˆ†ææ¨¡å‹è¡¨ç°
- ğŸ“‹ **é”™è¯¯æ ·æœ¬æ”¶é›†**ï¼šé‡ç‚¹å…³æ³¨é”™è¯¯æ¡ˆä¾‹ï¼Œç”¨äºåç»­æ”¹è¿›
- ğŸ’¾ **ç»“æœå¯¼å‡º**ï¼šCSVã€JSON æ ¼å¼ï¼Œä¾¿äºè¿›ä¸€æ­¥åˆ†æ

### 8.4 è¯„æµ‹æ•°æ®å‡†å¤‡å»ºè®®

**æ¨èé¢˜åº“**ï¼š
- **PCEB/CPsyExam**ï¼šçŸ¥è¯†/ä¼¦ç†/æ¡ˆä¾‹ç»¼åˆè¯„æµ‹
- **PsyQA**ï¼šåŒç†å¿ƒã€æ”¯æŒæ€§å›ç­”è´¨é‡
- **C-Eval/CMMLU**ï¼šå¿ƒç†å­¦å­é›†çŸ¥è¯†æµ‹è¯•

**æ•°æ®æ ¼å¼**ï¼š
```json
# å•é€‰é¢˜
{"id":"q1","question":"é—®é¢˜æè¿°","choices":["é€‰é¡¹A","é€‰é¡¹B","é€‰é¡¹C","é€‰é¡¹D"],"answer":"B"}

# å¤šé€‰é¢˜
{"id":"q2","question":"é—®é¢˜æè¿°","choices":["é€‰é¡¹A","é€‰é¡¹B","é€‰é¡¹C","é€‰é¡¹D"],"answer":"B,C"}
```

## 9. å·²çŸ¥é—®é¢˜ä¸ä¿®å¤
- âœ… å·²è§£å†³ï¼š`--report_to swanlab` å‚æ•°ç¼ºå¤±å¯¼è‡´ä¸æ¨é€
- âœ… å·²è§£å†³ï¼šFlash Attention å®‰è£…æ”¯æŒ `--packing true`
- âœ… å·²è§£å†³ï¼šç½‘ç»œä»£ç†é—®é¢˜ï¼ˆè®¾ç½® NO_PROXY ç¯å¢ƒå˜é‡ï¼‰
- GPU ä¸æ”¯æŒ bf16ï¼šåˆ‡æ¢ä¸º `--fp16 true`
- æ˜¾å­˜ä¸è¶³ï¼šå¢å¤§ `--gradient_accumulation_steps`ã€å¼€å¯ `--gradient_checkpointing`ã€æˆ–ä½¿ç”¨ DeepSpeed `--deepspeed zero2/zero3`
- é•¿åº¦é™åˆ¶ï¼šå°† `--max_length` é™åˆ° 1024/1536 ä»¥é™ä½æ˜¾å­˜

## 10. ç»“æœä¸ç»“è®ºï¼ˆå ä½ï¼‰
- æŒ‡æ ‡æ±‡æ€»ï¼ˆSwanLab æˆªå›¾/é“¾æ¥ï¼‰ï¼šå¾…è¡¥
- æ ·ä¾‹å¯¹è¯ä¸ä¸»è§‚è¯„ä¼°ï¼šå¾…è¡¥
- å¯¹æ¯”åŸºçº¿ï¼ˆå¦‚æœªå¾®è°ƒ vs å¾®è°ƒï¼‰ï¼šå¾…è¡¥
- è¯„æµ‹ç»“æœï¼ˆé€‰æ‹©é¢˜å‡†ç¡®ç‡ã€ä¸»è§‚é¢˜è´¨é‡ç­‰ï¼‰ï¼šå¾…è¡¥

## 11. åç»­è®¡åˆ’
- å¢åŠ å¤šå¡ DeepSpeed é…ç½®ä¸ååç»Ÿè®¡
- å°è¯• Flash-Attnï¼ˆå¦‚ç¡¬ä»¶/é©±åŠ¨å…è®¸ï¼‰
- æ•°æ®æ¸…æ´—ä¸æ¨¡æ¿æ”¹è¿›ï¼ˆå¦‚éœ€ï¼‰
- æ‰©å±•å¿ƒç†å­¦åŸºå‡†è¯„æµ‹ï¼ˆPsyQAã€CPsyExam ç­‰ï¼‰
- è‡ªåŠ¨åŒ–è¯„æµ‹æµç¨‹ï¼ˆCI/CD é›†æˆï¼‰

## 12. å˜æ›´æ—¥å¿—
- åˆå§‹ç‰ˆæœ¬ï¼šæ•´ç†æœ¬æ¬¡å®éªŒçš„å…¨æµç¨‹å¹¶ç»Ÿä¸€å‘½ä»¤æ¨¡æ¿ï¼ˆå« `--report_to swanlab`ï¼‰
- æ›´æ–°ï¼šåŠ å…¥ Flash Attention å®‰è£…çŠ¶æ€ä¸æ”¯æŒ packing çš„è®­ç»ƒå‘½ä»¤
- æ›´æ–°ï¼šåŠ å…¥å®Œæ•´çš„æ¨¡å‹è¯„æµ‹æµç¨‹å’Œå·¥å…·é…ç½®
- æ›´æ–°ï¼šåŠ å…¥ä½¿ç”¨å¯¼å‡ºæ¨¡å‹è¿›è¡Œ EvalScope è¯„æµ‹çš„å®Œæ•´å‘½ä»¤å’Œæµç¨‹

## 13. å¯¼å‡ºæ¨¡å‹è¯„æµ‹å®Œæ•´æµç¨‹

### 13.1 è¯„æµ‹å‰å‡†å¤‡

**ç¡®è®¤å¯¼å‡ºæ¨¡å‹è·¯å¾„**ï¼š
```bash
# æ£€æŸ¥å¯¼å‡ºç›®å½•
ls -la ./export/
# åº”è¯¥çœ‹åˆ°ï¼šmh-sft-qwen2p5-7b/

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -la ./export/mh-sft-qwen2p5-7b/
# åº”è¯¥åŒ…å«ï¼šconfig.json, model.safetensors, tokenizer.json ç­‰
```

**åˆ›å»ºç»“æœç›®å½•**ï¼š
```bash
mkdir -p ./results
mkdir -p ./results/evalscope
mkdir -p ./results/analysis
```

### 13.2 ä½¿ç”¨ EvalScope è¯„æµ‹å¯¼å‡ºæ¨¡å‹

#### åŸºç¡€è¯„æµ‹ï¼ˆæ¨èå¼€å§‹ï¼‰
```bash
# è¯„æµ‹ä¸­æ–‡è¯­è¨€ç†è§£åŸºå‡†
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval \
  --limit 100 \
  --output-file ./results/evalscope/mh-sft-7b-ceval.json

# è¯„æµ‹ä¸­æ–‡å¤šä»»åŠ¡è¯­è¨€ç†è§£
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets cmmlu \
  --limit 100 \
  --output-file ./results/evalscope/mh-sft-7b-cmmlu.json
```

#### å¿ƒç†å­¦ä¸“é¡¹è¯„æµ‹
```bash
# è¯„æµ‹å¿ƒç†å­¦è€ƒè¯•é€‰æ‹©é¢˜
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets pceb_mcq \
  --limit 100 \
  --output-file ./results/evalscope/mh-sft-7b-pceb.json

# è¯„æµ‹å¿ƒç†å­¦é—®ç­”è´¨é‡
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets psyqa \
  --limit 100 \
  --output-file ./results/evalscope/mh-sft-7b-psyqa.json
```

#### ç»¼åˆè¯„æµ‹ï¼ˆä¸€æ¬¡æ€§è¯„æµ‹å¤šä¸ªæ•°æ®é›†ï¼‰
```bash
# è¯„æµ‹æ‰€æœ‰æ”¯æŒçš„åŸºå‡†
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval cmmlu pceb_mcq psyqa \
  --limit 100 \
  --output-file ./results/evalscope/mh-sft-7b-all-benchmarks.json
```

### 13.3 è¯„æµ‹ç»“æœåˆ†æ

#### å¯åŠ¨å¯è§†åŒ–ç•Œé¢
```bash
# å¯åŠ¨ä¸­æ–‡ç•Œé¢
evalscope app --lang zh

# å¯åŠ¨è‹±æ–‡ç•Œé¢
evalscope app --lang en

# é»˜è®¤åœ°å€ï¼šhttp://127.0.0.1:7860
```

#### ç»“æœæ–‡ä»¶åˆ†æ
```bash
# æŸ¥çœ‹è¯„æµ‹ç»“æœ
cat ./results/evalscope/mh-sft-7b-ceval.json | jq '.'

# æå–å…³é”®æŒ‡æ ‡
cat ./results/evalscope/mh-sft-7b-ceval.json | jq '.results | keys'

# æŸ¥çœ‹å…·ä½“åˆ†æ•°
cat ./results/evalscope/mh-sft-7b-ceval.json | jq '.results.ceval.metrics'
```

### 13.4 è¯„æµ‹å‚æ•°è°ƒä¼˜

#### æ€§èƒ½ä¼˜åŒ–
```bash
# å¢åŠ è¯„æµ‹æ ·æœ¬æ•°é‡ï¼ˆæ›´å‡†ç¡®çš„ç»“æœï¼‰
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval \
  --limit 500 \
  --output-file ./results/evalscope/mh-sft-7b-ceval-500.json

# ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿ
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval \
  --limit 100 \
  --num_workers 4 \
  --output-file ./results/evalscope/mh-sft-7b-ceval-fast.json
```

#### è‡ªå®šä¹‰è¯„æµ‹
```bash
# è¯„æµ‹ç‰¹å®šå­é›†
evalscope eval \
  --model ./export/mh-sft-qwen2p5-7b \
  --eval-type local \
  --datasets ceval \
  --limit 100 \
  --subset psychology \
  --output-file ./results/evalscope/mh-sft-7b-ceval-psychology.json
```

### 13.5 è¯„æµ‹ç»“æœè®°å½•æ¨¡æ¿

**è¯„æµ‹è®°å½•è¡¨**ï¼š
| æ•°æ®é›† | æ ·æœ¬æ•° | å‡†ç¡®ç‡ | F1åˆ†æ•° | å¤‡æ³¨ |
|--------|--------|--------|--------|------|
| C-Eval | 100    | -      | -      | å¾…è¯„æµ‹ |
| CMMLU  | 100    | -      | -      | å¾…è¯„æµ‹ |
| PCEB   | 100    | -      | -      | å¾…è¯„æµ‹ |
| PsyQA  | 100    | -      | -      | å¾…è¯„æµ‹ |

**æ€§èƒ½å¯¹æ¯”**ï¼š
- åŸºåº§æ¨¡å‹ vs å¾®è°ƒåæ¨¡å‹
- ä¸åŒè®­ç»ƒè½®æ•°çš„æ€§èƒ½å˜åŒ–
- ä¸å…¶ä»–åŒç±»æ¨¡å‹çš„å¯¹æ¯”

### 13.6 å¸¸è§é—®é¢˜è§£å†³

**è¯„æµ‹å¤±è´¥æ’æŸ¥**ï¼š
```bash
# 1. æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la ./export/mh-sft-qwen2p5-7b/

# 2. æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§
python -c "from transformers import AutoModel, AutoTokenizer; model = AutoModel.from_pretrained('./export/mh-sft-qwen2p5-7b'); print('Model loaded successfully')"

# 3. æ£€æŸ¥ EvalScope å®‰è£…
evalscope --version

# 4. æ£€æŸ¥å¯ç”¨æ•°æ®é›†
evalscope list-datasets
```

**æ˜¾å­˜ä¸è¶³**ï¼š
```bash
# å‡å°‘è¯„æµ‹æ ·æœ¬æ•°é‡
--limit 50

# ä½¿ç”¨æ›´å°çš„æ‰¹æ¬¡
--batch_size 1

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
--gradient_checkpointing true
```

---

**æ³¨æ„**: ä½¿ç”¨å¯¼å‡ºæ¨¡å‹è¿›è¡Œè¯„æµ‹çš„ä¼˜åŠ¿æ˜¯æ— éœ€å¯åŠ¨æœåŠ¡ï¼Œç›´æ¥åŠ è½½æ¨¡å‹æƒé‡ï¼Œè¯„æµ‹é€Ÿåº¦æ›´å¿«ï¼Œèµ„æºå ç”¨æ›´å°‘ã€‚å»ºè®®å…ˆç”¨å°æ ·æœ¬æµ‹è¯•ï¼Œç¡®è®¤æ— é—®é¢˜åå†è¿›è¡Œå®Œæ•´è¯„æµ‹ã€‚



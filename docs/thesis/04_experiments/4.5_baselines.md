# 4.5 Baselines

## 4.5.1 Zero-shot Instruction Models
- Qwen2.5-7B-Instruct (no fine-tuning)
- InternLM2.5-7B-Chat (no fine-tuning)

## 4.5.2 Domain-adapted Models (ours)
- Qwen2.5-7B SFT (LoRA r=8, alpha=32)
- GPT-OSS-20B SFT (LoRA r=16, alpha=64)
- InternLM2.5-7B SFT (LoRA r=8, alpha=32)

## 4.5.3 Prior Works (reference)
- CounselBench leaderboards (where available)
- MMLU/MMLU-Pro published numbers (for approximate context)

## 4.5.4 Rationale
We compare strong zero-shot instruction models against our domain-adapted variants to quantify the gains from supervised fine-tuning on psychological counseling dialogues.

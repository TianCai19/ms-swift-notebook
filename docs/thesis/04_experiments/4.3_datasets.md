# 4.3 Datasets

## 4.3.1 Training Dataset
- Name: CodyWhy/mh-sharegpt-20250820
- Format: ShareGPT JSONL
- Language: Chinese (major), English (minor)
- Size: ~5K dialogues

### Preprocessing
- Auto template detection by ms-swift
- Cleaning: remove toxic/unsafe items; normalize roles; trim over-length
- Train/val split: 95/5

## 4.3.2 Evaluation Datasets
- GSM8K (math reasoning): limit=100 (quick), full (final)
- C-Eval (Chinese understanding): limit=100 per domain
- CMMLU (Chinese multi-task): limit=100
- MMLU (psychology subsets): professional_psychology, high_school_psychology
- MMLU-Pro (psychology): psychology subset, few_shot_num=5
- MMLU-Redux (psychology, efficient)
- Super-GPQA (Psychology)

### EvalScope Invocation (checkpoint)
```bash
evalscope eval \
  --model ./output/qwen2.5-7b-sft/v1-xxx/checkpoint-xxx \
  --datasets gsm8k ceval cmmlu mmlu mmlu_pro super_gpqa \
  --dataset-args '{
    "mmlu": {"subset_list": ["professional_psychology", "high_school_psychology"], "few_shot_num": 0, "few_shot_random": false, "metric_list": ["AverageAccuracy"]},
    "mmlu_pro": {"subset_list": ["psychology"], "few_shot_num": 5, "few_shot_random": false, "metric_list": ["AverageAccuracy"]}
  }' \
  --limit 100 \
  --eval-type checkpoint
```
